{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"../images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Build a Named-Entity Recognizer\n",
    "\n",
    "In this notebook, you'll build an application that finds disease names in medical disease abstracts. The model does not \"search\" for names from a list, but rather \"recognizes\" that certain words are disease references from the context of the language.\n",
    "\n",
    "**[4.1 Set Up the Project](#4.1-Set-Up-the-Project)**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.1.1 Input Parameters](#4.1.1-Input-Parameters)<br>\n",
    "**[4.2 Create Neural Modules](#4.2-Create-Neural-Modules)**<br>\n",
    "**[4.3 Create Neural Graphs](#4.3-Create-Neural-Graphs)**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.3.1 Training Graph](#4.3.1-Training-Graph)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.3.2 Exercise: Create the Validation Graph](#4.3.2-Exercise:-Create-the-Validation-Graph)<br>\n",
    "**[4.4 Training](#4.4-Training)**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.4.1 Set the Learning Rate and Optimizer](#4.4.1-Set-the-Learning-Rate-and-Optimizer)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.4.2 Exercise: Create the Callbacks](#4.4.2-Exercise:-Create-the-Callbacks)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.4.3 Run the Trainer](#4.4.3-Run-the-Trainer)<br>\n",
    "**[4.5 Inference](#4.5-Inference)**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.5.1 Create the Test Graph](#4.5.1-Create-the-Test-Graph)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.5.2 Run Inference on the Test Queries](#4.5.2-Run-Inference-on-the-Test-Queries)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.5.3 Inference Results](#4.5.3-Inference-Results)<br>\n",
    "**[4.6 Exercise: Change the Language Model](#4.6-Exercise:-Change-the-Language-Model)**<br>\n",
    "\n",
    "As we saw in the [1.0 Explore the Data](010_ExploreData.ipynb) notebook, the dataset for the NER project is made up of sentences with IOB tagging, where each word in a sentence is tagged as inside, outside, or the beginning of a named entity.  In the NER task, you'll follow the same basic steps as in the text classification task to build your project, train it, and test it, with a few differences:\n",
    "* You'll learn to apply the *domain-specific* [BioBERT](https://news.developer.nvidia.com/biobert-optimized/) language model from an imported checkpoint, instead of one of the default pretrained models\n",
    "* You'll use different neural modules appropriate for use with NER\n",
    "* You'll learn to use a query-based technique for inference\n",
    "\n",
    "BioBERT has the same network architecture as the original BERT, but instead of Wikipedia and BookCorpus, it is pretrained on PubMed, a large biomedical text corpus.  Starting with BioBERT instead of BERT achieves better performance in biomedical downstream tasks, such as question answering(QA), named entity recognition(NER) and relationship extraction(RE). This model was trained for 1M steps. For more information please refer to the original paper: [BioBERT: a pre-trained biomedical language representation model for biomedical text mining](https://academic.oup.com/bioinformatics/article/36/4/1234/5566506)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Set Up the Project\n",
    "The NeMo setup pattern is the same for NER as for text classification, but some of the details are different.\n",
    "* The \"input data\" consists of two files instead of one (text and labels)\n",
    "* The data layers and classifiers work with \"tokens\" \n",
    "* We need to define a \"none\" label for the token padding, which we'll designate as \"O\", the symbol for \"outside\" in IOB\n",
    "\n",
    "<img src=\"../images/nemo/nm-pipe.png\" width=800>\n",
    "\n",
    "Begin by importing libraries.  Note the specific classes and helpers that are imported below.  These are the ones you'll use to build your training, validation, and testing graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-07-25 22:13:54 audio_preprocessing:56] Could not import torchaudio. Some features might not work.\n"
     ]
    }
   ],
   "source": [
    "# Import useful math and utility libraries\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import errno\n",
    "import inspect\n",
    "import termcolor\n",
    "\n",
    "# Import the nemo toolkit and NLP libraries\n",
    "import nemo\n",
    "import nemo.collections.nlp as nemo_nlp\n",
    "\n",
    "# Import the specific neural modules and module helpers we need\n",
    "from nemo.collections.nlp.nm.data_layers import BertTokenClassificationDataLayer\n",
    "from nemo.collections.nlp.nm.data_layers import BertTokenClassificationInferDataLayer\n",
    "from nemo.collections.nlp.nm.trainables import get_pretrained_lm_model\n",
    "from nemo.collections.nlp.nm.trainables import TokenClassifier\n",
    "from nemo.backends.pytorch.common.losses import CrossEntropyLossNM\n",
    "\n",
    "# Import helpers for fetching learning rate policy, tokenizer, vocabulary\n",
    "from nemo.utils.lr_policies import get_lr_policy\n",
    "from nemo.collections.nlp.data.tokenizers import get_tokenizer\n",
    "from nemo.collections.nlp.utils.data_utils import get_vocab\n",
    "\n",
    "# Import callbacks and callback functions\n",
    "from nemo.core import SimpleLogger, TensorboardLogger, EvaluatorCallback, CheckpointCallback\n",
    "from nemo.collections.nlp.callbacks.token_classification_callback import eval_epochs_done_callback, eval_iter_callback\n",
    "from nemo import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1 Input Parameters\n",
    "The training text and label files are `text_train.txt` and `labels_train`, respectively.  The validation and test files follow a similar naming pattern. Verify the location of the data files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.0M\n",
      "-rw-r--r-- 1 702112 10513  181K Jul 13 21:10 dev.tsv\n",
      "-rw-r--r-- 1 702112 10513     5 Jul 13 21:10 label_ids.csv\n",
      "-rw-r--r-- 1 702112 10513    52 Jul 13 21:10 label_stats.tsv\n",
      "-rw-r--r-- 1 702112 10513   48K Jul 13 21:10 labels_dev.txt\n",
      "-rw-r--r-- 1 702112 10513   49K Jul 13 21:10 labels_test.txt\n",
      "-rw-r--r-- 1 702112 10513  271K Jul 13 21:10 labels_train.txt\n",
      "-rw-r--r-- 1 702112 10513  185K Jul 13 21:10 test.tsv\n",
      "-rw-r--r-- 1 702112 10513  135K Jul 13 21:10 text_dev.txt\n",
      "-rw-r--r-- 1 702112 10513  138K Jul 13 21:10 text_test.txt\n",
      "-rw-r--r-- 1 702112 10513  758K Jul 13 21:10 text_train.txt\n",
      "-rw-r--r-- 1 702112 10513 1023K Jul 13 21:10 train.tsv\n",
      "-rw-r--r-- 1 702112 10513  1.2M Jul 13 21:10 train_dev.tsv\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /dli/task/data/NCBI_ner-3/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOB Tagging\n",
    "Recall that the sentences and labels in the NER dataset map to each other with _inside, outside, beginning (IOB)_ tagging.\n",
    "This mechanism can be used in a general way for multiple named entity types:\n",
    "* B-{CHUNK_TYPE} – for the word in the Beginning chunk\n",
    "* I-{CHUNK_TYPE} – for words Inside the chunk\n",
    "* O – Outside any chunk\n",
    "\n",
    "In our case, we are only looking for \"disease\" as our entity (or chunk) type, so we don't need to identify beyond the three classes: I, O, and B.\n",
    "**Three classes**\n",
    "* B - Begiining of disease name\n",
    "* I - Inside word of disease name\n",
    "* O - Outside of all disease names\n",
    "\n",
    "```text\n",
    "Identification of APC2 , a homologue of the adenomatous polyposis coli tumour suppressor .\n",
    "O              O  O    O O O         O  O   B           I         I    I      O          O  \n",
    "```\n",
    "\n",
    "If we were looking for two kinds of named entities, such as nouns and verbs in a parts-of-speech analysis, we would use a five-class IOB scheme:<br>\n",
    "**Five classes**\n",
    "* B-N - Beginning of noun word or phrase\n",
    "* I-N - Inside noun word or phrase\n",
    "* B-V - Beginning of verb word or phrase\n",
    "* I-V - Inside verb word or phrase\n",
    "* O   - Outside all nouns and verbs\n",
    "\n",
    "If you are intereested in learning more, take a look at [this paper](http://cs229.stanford.edu/proj2005/KrishnanGanapathy-NamedEntityRecognition.pdf) on the subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain-Specific Checkpoint\n",
    "We also need the checkpoints and configuration files for our domain-specific language models.  Specific checkpoints pretrained for BioBERT and BioMegatron can be downloaded from [NVIDIA NGC Models](https://ngc.nvidia.com/catalog/models):<br><br>\n",
    "For BioBERT  https://ngc.nvidia.com/catalog/models/nvidia:biobertbasecasedfornemo.<br>\n",
    "For BioMegatron  https://ngc.nvidia.com/catalog/models/nvidia:biomegatron345muncased.\n",
    "\n",
    "**You don't need to download them for this course**, as that has already been done.  Run the next cell to see where the checkpoint files (.pt) and config files (.json) are located in the file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ngc_checkpoints\n",
      "└── checkpoints\n",
      "    ├── biobert\n",
      "    │   ├── BERT.pt\n",
      "    │   ├── SequenceClassifier.pt\n",
      "    │   ├── TokenClassifier.pt\n",
      "    │   └── bert_config.json\n",
      "    └── biomegatron\n",
      "        ├── MegatronBERT.pt\n",
      "        ├── config.json\n",
      "        └── vocab.txt\n",
      "\n",
      "3 directories, 7 files\n"
     ]
    }
   ],
   "source": [
    "!tree /ngc_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set up all the locations and pre-set parameters for the model.  If you want to try a different model later, you can restart the notebook kernel, then change MODEL_TYPE here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the input data location\n",
    "DATA_DIR = '/dli/task/data/NCBI_ner-3/'\n",
    "\n",
    "# Identify downloaded checkpoints location\n",
    "CHECKPOINTS_PATH = '/ngc_checkpoints/checkpoints/' \n",
    "\n",
    "# Select which model you want to use, either biobert or biomegatron\n",
    "MODEL_TYPE = \"biobert\"\n",
    "# MODEL_TYPE = \"biomegatron\"\n",
    "\n",
    "# Set the number of words in the sequences\n",
    "# Shorter sequences will be padded with NONE_LABEL, longer ones truncated\n",
    "MAX_SEQ_LEN = 128 \n",
    "BATCH_SIZE = 16\n",
    "NONE_LABEL = \"O\" \n",
    "NUM_CLASSES = 3 # IOB (inside, outside, beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dictionaries for other parameters that key off the MODEL_TYPE\n",
    "PRETRAINED_MODEL_NAME = {'biobert': 'bert-base-cased', \n",
    "                         'biomegatron': 'megatron-bert-uncased'}\n",
    "DO_LOWER_CASE = {'biobert': False, \n",
    "               'biomegatron': True}\n",
    "WORK_DIR = {'biobert': '/dli/task/data/logs-ner-biobert/', \n",
    "            'biomegatron': '/dli/task/data/logs-ner-biomegatron'}\n",
    "\n",
    "# Map downloaded ngc models to MODEL_TYPE\n",
    "NGC_CHECKPOINT = {'biobert': CHECKPOINTS_PATH + 'biobert/BERT.pt', \n",
    "                  'biomegatron': CHECKPOINTS_PATH + 'biomegatron/MegatronBERT.pt'}\n",
    "NGC_CONFIG = {'biobert': CHECKPOINTS_PATH + 'biobert/bert_config.json', \n",
    "              'biomegatron': CHECKPOINTS_PATH + 'biomegatron/config.json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Create Neural Modules\n",
    "\n",
    "<figure>\n",
    "    <img src=\"../images/nemo/ner_graph.png\" width=800>\n",
    "    <figcaption style=\"text-align:center;\">NER Graph</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, begin by instantiating the neural module factory before building anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the neural module factory\n",
    "nf = nemo.core.NeuralModuleFactory(log_dir=WORK_DIR[MODEL_TYPE],\n",
    "                                   create_tb_writer=True,\n",
    "                                   placement=nemo.core.DeviceType.GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and validation each need a datalayer neural module instantiatted with `BertTokenClassificationDataLayer`.  As a reminder of the inputs required, inspect the signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (text_file, label_file, tokenizer, max_seq_length, pad_label='O', label_ids=None, num_samples=-1, shuffle=False, batch_size=64, ignore_extra_tokens=False, ignore_start_end=False, use_cache=False, dataset_type=<class 'nemo.collections.nlp.data.datasets.token_classification_dataset.BertTokenClassificationDataset'>)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.signature(BertTokenClassificationDataLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `text_file`, `label_file`, `tokenizer`, `max_seq_length` are all required. The only one of those four items we don't have yet is the tokenizer, so we'll set it up before we set up the data layers.  \n",
    "\n",
    "Of the optional parameters, it looks like the default for pad_label is the one we want already, but shuffle needs to be set to `True` for training, and for convenience we want to use a cache, so `use_cache` needs to be `True`.  We also need to use a different value for `batch_size`. The rest is good to go.\n",
    "\n",
    "In the next cell, the tokenizer and training data layer neural module are instantiated to get you started.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-07-25 22:13:58 bert_tokenizer:78] Deriving bert model type from pretrained model name.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d50842aa92495f85174852f9dc6e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=213450, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo I 2020-07-25 22:13:59 token_classification_dataset:273] Creating a new label to label_id dictionary. It's recommended to use label_ids generated during training for dev/test sets to avoid errors if some labels are not present in the dev/test sets. For training set label_ids should be None.\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:116] Max length: 128\n",
      "[NeMo I 2020-07-25 22:14:06 data_preprocessing:250] Min: 4 |                  Max: 178 |                  Mean: 35.938237463126846 |                  Median: 34.0\n",
      "[NeMo I 2020-07-25 22:14:06 data_preprocessing:252] 75 percentile: 45.0\n",
      "[NeMo I 2020-07-25 22:14:06 data_preprocessing:253] 99 percentile: 88.76999999999953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-07-25 22:14:06 token_classification_dataset:145] 8 are longer than 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:149] i: 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:150] subtokens: [CLS] I ##dent ##ification of AP ##C ##2 , a ho ##mo ##logue of the ad ##eno ##mat ##ous p ##oly ##po ##sis co ##li t ##umour suppress ##or . [SEP]\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:153] subtokens_mask: 0 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:155] labels: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:149] i: 1\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:150] subtokens: [CLS] The ad ##eno ##mat ##ous p ##oly ##po ##sis co ##li ( AP ##C ) t ##umour - suppress ##or protein controls the W ##nt signalling pathway by forming a complex with g ##ly ##co ##gen s ##ynth ##ase kinase 3 ##bet ##a ( G ##S ##K - 3 ##bet ##a ) , a ##xin / conduct ##in and beta ##cate ##nin . [SEP]\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:153] subtokens_mask: 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:155] labels: 0 0 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:149] i: 2\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:150] subtokens: [CLS] Complex formation induce ##s the rapid degradation of beta ##cate ##nin . [SEP]\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:153] subtokens_mask: 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:155] labels: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:149] i: 3\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:150] subtokens: [CLS] In co ##lon car ##cin ##oma cells , loss of AP ##C leads to the accumulation of beta ##cate ##nin in the nucleus , where it binds to and activate ##s the T ##c ##f - 4 transcription factor ( reviewed in [ 1 ] [ 2 ] ) . [SEP]\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:153] subtokens_mask: 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:155] labels: 0 0 1 1 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:149] i: 4\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:150] subtokens: [CLS] Here , we report the identification and g ##eno ##mic structure of AP ##C ho ##mo ##logue ##s . [SEP]\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:153] subtokens_mask: 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:155] labels: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:295] features saved to /dli/task/data/NCBI_ner-3/cached_text_train.txt_BertTokenizer_128_28996\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:298] labels to ids dict saved to /dli/task/data/NCBI_ner-3/label_ids.pkl\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:310] Three most popular labels\n",
      "[NeMo I 2020-07-25 22:14:06 data_preprocessing:81] 0 item: 0, 669810 out of 694272, 0.9647659706858407.\n",
      "[NeMo I 2020-07-25 22:14:06 data_preprocessing:81] 1 item: 1, 12896 out of 694272, 0.01857485250737463.\n",
      "[NeMo I 2020-07-25 22:14:06 data_preprocessing:81] 2 item: 2, 11566 out of 694272, 0.01665917680678466.\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:317] Labels: {'O': 0, 'B': 1, 'I': 2}\n",
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:318] Labels mapping saved to : /dli/task/data/NCBI_ner-3/label_ids.csv\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the data Layer neural module for training.\n",
    "#     Include the input file locations, tokenizer, max_seq_length, and batch size.\n",
    "#     Set the shuffle and use_cache to True for training \n",
    "USE_CACHE = True\n",
    "tokenizer = get_tokenizer(\n",
    "    tokenizer_name='nemobert',\n",
    "    pretrained_model_name = PRETRAINED_MODEL_NAME[MODEL_TYPE],\n",
    "    do_lower_case=DO_LOWER_CASE[MODEL_TYPE]\n",
    ")\n",
    "dl_train = BertTokenClassificationDataLayer(\n",
    "    text_file=os.path.join(DATA_DIR,'text_train.txt'),\n",
    "    label_file=os.path.join(DATA_DIR,'labels_train.txt'),\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=MAX_SEQ_LEN,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    use_cache=USE_CACHE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next four cells, instantiate:\n",
    "1. Validation data layer neural module\n",
    "1. Language model neural module\n",
    "1. Token classification model neural module\n",
    "1. Loss neural module\n",
    "\n",
    "Look for and fix the <i><strong><span style=\"color:green;\">#FIXME</span><strong></i> code lines.  If you get stuck, look back at the [2.0 NLP Projects with NeMo](020_ExploreNeMo.ipynb) notebook for inspiration or the [solution notebook](solution_notebooks/SOLN_040_NamedEntityRecogntion.ipynb) for the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-07-25 22:14:06 token_classification_dataset:273] Creating a new label to label_id dictionary. It's recommended to use label_ids generated during training for dev/test sets to avoid errors if some labels are not present in the dev/test sets. For training set label_ids should be None.\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:116] Max length: 122\n",
      "[NeMo I 2020-07-25 22:14:08 data_preprocessing:250] Min: 4 |                  Max: 122 |                  Mean: 36.812567713976165 |                  Median: 34.0\n",
      "[NeMo I 2020-07-25 22:14:08 data_preprocessing:252] 75 percentile: 47.0\n",
      "[NeMo I 2020-07-25 22:14:08 data_preprocessing:253] 99 percentile: 83.55999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-07-25 22:14:08 token_classification_dataset:145] 0 are longer than 122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:149] i: 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:150] subtokens: [CLS] BR ##CA ##1 is secret ##ed and exhibits properties of a g ##rani ##n . [SEP]\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:153] subtokens_mask: 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:155] labels: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:149] i: 1\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:150] subtokens: [CLS] G ##er ##m ##line mutations in BR ##CA ##1 are responsible for most cases of inherited breast and o ##var ##ian cancer . [SEP]\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:153] subtokens_mask: 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:155] labels: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:149] i: 2\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:150] subtokens: [CLS] However , the function of the BR ##CA ##1 protein has remained el ##usive . [SEP]\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:153] subtokens_mask: 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:155] labels: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:149] i: 3\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:150] subtokens: [CLS] We now show that BR ##CA ##1 en ##codes a 190 - k ##D protein with sequence ho ##mology and bio ##chemical analogy to the g ##rani ##n protein family . [SEP]\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:153] subtokens_mask: 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:155] labels: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:149] i: 4\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:150] subtokens: [CLS] Interest ##ingly , BR ##CA ##2 also includes a motif similar to the g ##rani ##n consensus at the C terminus of the protein . [SEP]\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:153] subtokens_mask: 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:155] labels: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:295] features saved to /dli/task/data/NCBI_ner-3/cached_text_dev.txt_BertTokenizer_128_28996\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:298] labels to ids dict saved to /dli/task/data/NCBI_ner-3/label_ids.pkl\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:310] Three most popular labels\n",
      "[NeMo I 2020-07-25 22:14:08 data_preprocessing:81] 0 item: 0, 108953 out of 112606, 0.967559455091203.\n",
      "[NeMo I 2020-07-25 22:14:08 data_preprocessing:81] 1 item: 2, 2013 out of 112606, 0.017876489707475622.\n",
      "[NeMo I 2020-07-25 22:14:08 data_preprocessing:81] 2 item: 1, 1640 out of 112606, 0.014564055201321422.\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:317] Labels: {'O': 0, 'B': 1, 'I': 2}\n",
      "[NeMo I 2020-07-25 22:14:08 token_classification_dataset:318] Labels mapping saved to : /dli/task/data/NCBI_ner-3/label_ids.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the data Layer neural module for validation.\n",
    "#     Include the input file locations, tokenizer, max_seq_length, and batch size.\n",
    "#     Set the shuffle to False (the default value) and use_cache to True for validation  \n",
    "dl_val = BertTokenClassificationDataLayer(\n",
    "    text_file=os.path.join(DATA_DIR,'text_dev.txt'),\n",
    "    label_file=os.path.join(DATA_DIR,'labels_dev.txt'),\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=MAX_SEQ_LEN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    use_cache=USE_CACHE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-07-25 22:14:12 common_utils:85] bert-base-cased model restored from /ngc_checkpoints/checkpoints/biobert/BERT.pt\n",
      "bert-base-cased has 108310272 weights\n"
     ]
    }
   ],
   "source": [
    "# 2. Instantiate the Language Model with the get_pretrained_lm_model function\n",
    "#    Since we are defining the checkpoint, include the file locations as values for\n",
    "#    \"config=\", \"pretrained_model_name=\", and \"checkpoint=\"\n",
    "#    Hint: We set these values up earlier with dictionaries keyed off the MODEL_TYPE\n",
    "lm = get_pretrained_lm_model(config=NGC_CONFIG[MODEL_TYPE],\n",
    "                                pretrained_model_name=PRETRAINED_MODEL_NAME[MODEL_TYPE],\n",
    "                                checkpoint=NGC_CHECKPOINT[MODEL_TYPE]\n",
    "    )\n",
    "\n",
    "# Sanity check the number of weight parameters\n",
    "#    It should be 108,310,272 for `bert-base-cased`\n",
    "print(f'{PRETRAINED_MODEL_NAME[MODEL_TYPE]} has {lm.num_weights} weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier has 2307 weights\n"
     ]
    }
   ],
   "source": [
    "# 3. Instantiate the TokenClassifier\n",
    "#    Include the hidden_size, num_classes (which is 3), num_layers (set to 1), \n",
    "#    and a dropout rate of 0.1\n",
    "lm_hidden_size = lm.hidden_size\n",
    "classifier = TokenClassifier(hidden_size=lm_hidden_size, \n",
    "            num_classes=NUM_CLASSES, \n",
    "            dropout=0.1, \n",
    "            num_layers=1)\n",
    "\n",
    "# Sanity check the number of weight parameters\n",
    "#    It should be 2307\n",
    "print(f'Classifier has {classifier.num_weights} weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Instantiate the CrossEntropyLossNM Loss Function \n",
    "#  Set the logits_ndim value to 3\n",
    "loss = CrossEntropyLossNM(logits_ndim=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job!  Your neural modules are set up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Create Neural Graphs\n",
    "\n",
    "Define the neural graphs by linking the output of each neural module with the input of the next one in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.1 Training Graph\n",
    "\n",
    "<figure>\n",
    "    <img src=\"../images/nemo/ner_train_graph.png\" width=800>\n",
    "    <figcaption style=\"text-align:center;\">Training Graph</figcaption>\n",
    "</figure>\n",
    "As before, we'll use the outputs for each neural module to define the inputs of the next one in the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data output from the data layer\n",
    "train_data = dl_train()\n",
    "\n",
    "# Define train_embeddings from the language model, based on inputs from the data layer  \n",
    "train_embeddings = lm(input_ids=train_data.input_ids, token_type_ids=train_data.input_type_ids, attention_mask=train_data.input_mask)\n",
    "\n",
    "# Define the train_logits from the clasifier, based on the embeddings from the language model\n",
    "train_logits = classifier(hidden_states=train_embeddings)\n",
    "\n",
    "# Define the train_loss based on the classifier logits and data layer labels\n",
    "train_loss = loss(logits=train_logits, labels=train_data.labels, loss_mask=train_data.loss_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that the `train_data` assignment is slightly more concise than the explicit tuple we used in the text classification notebook.  \n",
    "We set `train_data = dl_train()` to create the link in our graph from the data layer and into the language model.  The variable names are defined in NeMo, giving us convenient access, e.g. `train_data.input_ids`, `train_data.input_type_ids`, and so on.  Here's a list from the [`BertTokenClassificationDataLayer` source code](https://github.com/NVIDIA/NeMo/blob/3d6ae0589c1bf0fed2cb038ac80590bebe738e3d/nemo/collections/nlp/nm/data_layers/token_classification_datalayer.py):\n",
    "\n",
    "```python\n",
    "    def output_ports(self):\n",
    "        \"\"\"Returns definitions of module output ports.\n",
    "        input_ids:\n",
    "            indices of tokens which constitute batches of text segments\n",
    "        input_type_ids:\n",
    "            tensor with 0's and 1's to denote the text segment type\n",
    "        input_mask:\n",
    "            bool tensor with 0s in place of tokens to be masked\n",
    "        loss_mask:\n",
    "            used to mask and ignore tokens in the loss function\n",
    "        subtokens_mask:\n",
    "            used to mask all but the first subtoken of the work, could be useful during inference\n",
    "        labels:\n",
    "            token target ids\n",
    "        \"\"\"\n",
    " ```           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.2 Exercise: Create a Validation Graph\n",
    "\n",
    "The validation graph is very similar to the training graph. In fact, only the data layer module is different. \n",
    "\n",
    "<figure>\n",
    "    <img src=\"../images/nemo/ner_val_graph.png\" width=800>\n",
    "    <figcaption style=\"text-align:center;\">Validation Graph</figcaption>\n",
    "</figure>\n",
    "\n",
    "In the cell below, look for and fix the <i><strong><span style=\"color:green;\">#FIXME</span><strong></i> code lines (there are four of them).  If you get stuck, look back at the training graph you just set up for inspiration or the [solution notebook](solution_notebooks/SOLN_040_NamedEntityRecognition.ipynb) for the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data output from the data layer\n",
    "val_data = dl_val()\n",
    "\n",
    "# Define val_embeddings from the language model, based on inputs from the data layer  \n",
    "val_embeddings = lm(input_ids=val_data.input_ids, \n",
    "                       token_type_ids=val_data.input_type_ids, \n",
    "                       attention_mask=val_data.input_mask)\n",
    "\n",
    "# Define val_logits from the classifier, based on the embeddings from the language model\n",
    "val_logits = classifier(hidden_states=val_embeddings)\n",
    "\n",
    "# Define val_loss based on the classifier logits and data layer labels\n",
    "val_loss = loss(logits=val_logits, labels=val_data.labels, loss_mask=val_data.loss_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  You're pipelines are ready for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Training\n",
    "Now that the graphs are set up, the action can begin.  You'll train the model with the NeuralModuleFactory `.train()` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.1 Set the Learning Rate and Optimizer\n",
    "For NER, we'll set the learning rate to 0.00004 and use `WarmupAnnealing`.  We'll use the popular [`adam_w`](https://huggingface.co/transformers/main_classes/optimizer_schedules.html#adamw-pytorch) optimizer (with \"weight decay\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-07-25 22:14:12 <ipython-input-15-cf826b6bfd52>:10] doing 339 steps per epoch\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 4\n",
    "OPTIMIZER = 'adam_w'\n",
    "LEARNING_RATE = 4e-5\n",
    "WARMUP_RATIO = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "# If you're training on multiple GPUs, this should be\n",
    "# len(train_data_layer) // (batch_size * batches_per_step * num_gpus)\n",
    "steps_per_epoch = len(dl_train) // BATCH_SIZE\n",
    "logging.info(f\"doing {steps_per_epoch} steps per epoch\")\n",
    "lr_policy_fn = get_lr_policy(\"WarmupAnnealing\", \n",
    "                             total_steps=NUM_EPOCHS * steps_per_epoch, \n",
    "                             warmup_ratio=WARMUP_RATIO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.2 Exercise: Create the Callbacks\n",
    "NeMo has a callback system that can be used to inject user code and logic inside its training loop. You can find references for the newest built-in callbacks in the NeMo Documentation:  \n",
    "\n",
    "* [SimpleLogger](https://nvidia.github.io/NeMo/api-docs/nemo.html#nemo.core.callbacks.SimpleLogger)\n",
    "* [TensorboardLogger](https://nvidia.github.io/NeMo/api-docs/nemo.html#nemo.core.callbacks.TensorboardLogger)\n",
    "* [CheckpointCallBack](https://nvidia.github.io/NeMo/api-docs/nemo.html#nemo.core.callbacks.CheckpointCallback)\n",
    "\n",
    "In the cell below, create the callbacks, just as we did in the text classification project.  This time, specify a `step_freq=100` value. \n",
    "\n",
    "Look for and fix the <i><strong><span style=\"color:green;\">#FIXME</span><strong></i> code lines.  If you get stuck, look back at the [3.0 Build a 3-Class Text Classifier](030_TextClassification.ipynb) notebook for inspiration or the [solution notebook](solution_notebooks/SOLN_040_NamedEntityRecogntion.ipynb) for the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_callback = SimpleLogger(step_freq=100)\n",
    "\n",
    "tensorboard_callback = TensorboardLogger(nf.tb_writer, step_freq=steps_per_epoch)\n",
    "\n",
    "# Callback to evaluate the model\n",
    "eval_callback = EvaluatorCallback(\n",
    "        eval_tensors=[val_logits, val_data.labels, val_data.subtokens_mask],\n",
    "        user_iter_callback=lambda x, y: eval_iter_callback(x, y),\n",
    "        user_epochs_done_callback=lambda x: eval_epochs_done_callback(x, dl_train.dataset.label_ids,\n",
    "                                                                      f'{nf.work_dir}/graphs'),\n",
    "        tb_writer=nf.tb_writer,\n",
    "        eval_step=steps_per_epoch\n",
    "    )\n",
    "\n",
    "# Create callback to save checkpoints\n",
    "ckpt_callback = CheckpointCallback(folder=nf.checkpoint_dir,\n",
    "                                             epoch_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.3 Run the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-07-25 22:14:12 callbacks:534] Found 2 modules with weights:\n",
      "[NeMo I 2020-07-25 22:14:12 callbacks:536] BERT\n",
      "[NeMo I 2020-07-25 22:14:12 callbacks:536] tokenclassifier0\n",
      "[NeMo I 2020-07-25 22:14:12 callbacks:537] Total model parameters: 108312579\n",
      "[NeMo I 2020-07-25 22:14:12 callbacks:473] Found checkpoint folder /dli/task/data/logs-ner-biobert/checkpoints. Will attempt to restore checkpoints from it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-07-25 22:14:12 callbacks:499] For module BERT, no file matches  in /dli/task/data/logs-ner-biobert/checkpoints\n",
      "[NeMo W 2020-07-25 22:14:12 callbacks:501] Checkpoint folder /dli/task/data/logs-ner-biobert/checkpoints was present but nothing was restored. Continuing training from random initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-07-25 22:14:13 callbacks:232] loss: 1.1512176\n",
      "[NeMo I 2020-07-25 22:14:13 deprecated_callbacks:316] Doing Evaluation ..............................\n",
      "[NeMo I 2020-07-25 22:14:16 token_classification_callback:78] Sampled preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[NeMo I 2020-07-25 22:14:16 token_classification_callback:79] Sampled labels: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[NeMo I 2020-07-25 22:14:16 token_classification_callback:82] Accuracy: 0.2067670741374275\n",
      "[NeMo I 2020-07-25 22:14:16 token_classification_callback:86] F1 weighted: 29.83\n",
      "[NeMo I 2020-07-25 22:14:16 token_classification_callback:86] F1 macro: 15.34\n",
      "[NeMo I 2020-07-25 22:14:16 token_classification_callback:86] F1 micro: 20.68\n",
      "[NeMo I 2020-07-25 22:14:16 token_classification_callback:89]                  precision    recall  f1-score   support\n",
      "    \n",
      "    O (label id: 0)     0.9378    0.1912    0.3176     22092\n",
      "    B (label id: 1)     0.0354    0.8145    0.0679       787\n",
      "    I (label id: 2)     0.0671    0.0844    0.0748      1090\n",
      "    \n",
      "           accuracy                         0.2068     23969\n",
      "          macro avg     0.3468    0.3633    0.1534     23969\n",
      "       weighted avg     0.8686    0.2068    0.2983     23969\n",
      "    \n",
      "[NeMo I 2020-07-25 22:14:16 deprecated_callbacks:321] Evaluation time: 3.0950443744659424 seconds\n",
      "[NeMo I 2020-07-25 22:14:31 callbacks:232] loss: 0.14924724\n",
      "[NeMo I 2020-07-25 22:14:47 callbacks:232] loss: 0.16499284\n",
      "[NeMo I 2020-07-25 22:15:02 callbacks:232] loss: 0.05357892\n",
      "[NeMo I 2020-07-25 22:15:08 deprecated_callbacks:316] Doing Evaluation ..............................\n",
      "[NeMo I 2020-07-25 22:15:11 token_classification_callback:78] Sampled preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[NeMo I 2020-07-25 22:15:11 token_classification_callback:79] Sampled labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[NeMo I 2020-07-25 22:15:11 token_classification_callback:82] Accuracy: 0.9867745838374568\n",
      "[NeMo I 2020-07-25 22:15:11 token_classification_callback:86] F1 weighted: 98.68\n",
      "[NeMo I 2020-07-25 22:15:11 token_classification_callback:86] F1 macro: 93.03\n",
      "[NeMo I 2020-07-25 22:15:11 token_classification_callback:86] F1 micro: 98.68\n",
      "[NeMo I 2020-07-25 22:15:11 token_classification_callback:89]                  precision    recall  f1-score   support\n",
      "    \n",
      "    O (label id: 0)     0.9947    0.9937    0.9942     22092\n",
      "    B (label id: 1)     0.8612    0.9149    0.8872       787\n",
      "    I (label id: 2)     0.9210    0.8982    0.9094      1090\n",
      "    \n",
      "           accuracy                         0.9868     23969\n",
      "          macro avg     0.9256    0.9356    0.9303     23969\n",
      "       weighted avg     0.9870    0.9868    0.9868     23969\n",
      "    \n",
      "[NeMo I 2020-07-25 22:15:12 deprecated_callbacks:321] Evaluation time: 3.0679190158843994 seconds\n",
      "[NeMo I 2020-07-25 22:15:21 callbacks:232] loss: 0.102648206\n",
      "[NeMo I 2020-07-25 22:15:36 callbacks:232] loss: 0.027992608\n",
      "[NeMo I 2020-07-25 22:15:51 callbacks:232] loss: 0.04608334\n",
      "[NeMo I 2020-07-25 22:16:04 callbacks:465] Saved checkpoint: /dli/task/data/logs-ner-biobert/checkpoints/trainer-EPOCH-1.pt\n",
      "[NeMo I 2020-07-25 22:16:04 deprecated_callbacks:316] Doing Evaluation ..............................\n",
      "[NeMo I 2020-07-25 22:16:07 token_classification_callback:78] Sampled preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[NeMo I 2020-07-25 22:16:07 token_classification_callback:79] Sampled labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[NeMo I 2020-07-25 22:16:07 token_classification_callback:82] Accuracy: 0.9867328632817389\n",
      "[NeMo I 2020-07-25 22:16:07 token_classification_callback:86] F1 weighted: 98.68\n",
      "[NeMo I 2020-07-25 22:16:07 token_classification_callback:86] F1 macro: 93.2\n",
      "[NeMo I 2020-07-25 22:16:07 token_classification_callback:86] F1 micro: 98.67\n",
      "[NeMo I 2020-07-25 22:16:07 token_classification_callback:89]                  precision    recall  f1-score   support\n",
      "    \n",
      "    O (label id: 0)     0.9949    0.9931    0.9940     22092\n",
      "    B (label id: 1)     0.8761    0.9072    0.8914       787\n",
      "    I (label id: 2)     0.9056    0.9156    0.9106      1090\n",
      "    \n",
      "           accuracy                         0.9867     23969\n",
      "          macro avg     0.9255    0.9386    0.9320     23969\n",
      "       weighted avg     0.9869    0.9867    0.9868     23969\n",
      "    \n",
      "[NeMo I 2020-07-25 22:16:08 deprecated_callbacks:321] Evaluation time: 3.062488555908203 seconds\n",
      "[NeMo I 2020-07-25 22:16:11 callbacks:232] loss: 0.005354069\n",
      "[NeMo I 2020-07-25 22:16:26 callbacks:232] loss: 0.0027899658\n",
      "[NeMo I 2020-07-25 22:16:41 callbacks:232] loss: 0.010607562\n",
      "[NeMo I 2020-07-25 22:16:56 callbacks:232] loss: 0.009967881\n",
      "[NeMo I 2020-07-25 22:17:00 callbacks:465] Saved checkpoint: /dli/task/data/logs-ner-biobert/checkpoints/trainer-EPOCH-2.pt\n",
      "[NeMo I 2020-07-25 22:17:00 deprecated_callbacks:316] Doing Evaluation ..............................\n",
      "[NeMo I 2020-07-25 22:17:03 token_classification_callback:78] Sampled preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[NeMo I 2020-07-25 22:17:03 token_classification_callback:79] Sampled labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[NeMo I 2020-07-25 22:17:03 token_classification_callback:82] Accuracy: 0.9853143643873337\n",
      "[NeMo I 2020-07-25 22:17:04 token_classification_callback:86] F1 weighted: 98.54\n",
      "[NeMo I 2020-07-25 22:17:04 token_classification_callback:86] F1 macro: 92.35\n",
      "[NeMo I 2020-07-25 22:17:04 token_classification_callback:86] F1 micro: 98.53\n",
      "[NeMo I 2020-07-25 22:17:04 token_classification_callback:89]                  precision    recall  f1-score   support\n",
      "    \n",
      "    O (label id: 0)     0.9945    0.9926    0.9935     22092\n",
      "    B (label id: 1)     0.8453    0.9161    0.8793       787\n",
      "    I (label id: 2)     0.9072    0.8881    0.8975      1090\n",
      "    \n",
      "           accuracy                         0.9853     23969\n",
      "          macro avg     0.9157    0.9323    0.9235     23969\n",
      "       weighted avg     0.9856    0.9853    0.9854     23969\n",
      "    \n",
      "[NeMo I 2020-07-25 22:17:04 deprecated_callbacks:321] Evaluation time: 3.287924289703369 seconds\n",
      "[NeMo I 2020-07-25 22:17:16 callbacks:232] loss: 0.0051209927\n",
      "[NeMo I 2020-07-25 22:17:32 callbacks:232] loss: 0.006847029\n",
      "[NeMo I 2020-07-25 22:17:47 callbacks:232] loss: 0.0009159024\n",
      "[NeMo I 2020-07-25 22:17:57 callbacks:465] Saved checkpoint: /dli/task/data/logs-ner-biobert/checkpoints/trainer-EPOCH-3.pt\n",
      "[NeMo I 2020-07-25 22:17:57 deprecated_callbacks:339] Final Evaluation ..............................\n",
      "[NeMo I 2020-07-25 22:18:00 token_classification_callback:78] Sampled preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[NeMo I 2020-07-25 22:18:00 token_classification_callback:79] Sampled labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[NeMo I 2020-07-25 22:18:00 token_classification_callback:82] Accuracy: 0.986941466060328\n",
      "[NeMo I 2020-07-25 22:18:00 token_classification_callback:86] F1 weighted: 98.69\n",
      "[NeMo I 2020-07-25 22:18:00 token_classification_callback:86] F1 macro: 92.95\n",
      "[NeMo I 2020-07-25 22:18:00 token_classification_callback:86] F1 micro: 98.69\n",
      "[NeMo I 2020-07-25 22:18:00 token_classification_callback:89]                  precision    recall  f1-score   support\n",
      "    \n",
      "    O (label id: 0)     0.9933    0.9953    0.9943     22092\n",
      "    B (label id: 1)     0.8745    0.8945    0.8844       787\n",
      "    I (label id: 2)     0.9377    0.8835    0.9098      1090\n",
      "    \n",
      "           accuracy                         0.9869     23969\n",
      "          macro avg     0.9352    0.9245    0.9295     23969\n",
      "       weighted avg     0.9869    0.9869    0.9869     23969\n",
      "    \n",
      "[NeMo I 2020-07-25 22:18:00 deprecated_callbacks:344] Evaluation time: 3.079470634460449 seconds\n",
      "[NeMo I 2020-07-25 22:18:01 callbacks:465] Saved checkpoint: /dli/task/data/logs-ner-biobert/checkpoints/trainer-EPOCH-4.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATcAAAEECAYAAABNzHMxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAARXElEQVR4nO3dfaxlVX3G8e/DUF4U0DYzWmWYSmRQx6kC3lBbExWkOpgKpU0baAwSTSe1xVitpqiEWEyrhdakVpo4prbVRlGM2kkdQaVaXwo6w4soIy8jRl6q5bVWEQTu/fWPc4AzNzP3nnPmnjn7rvl+kp2cvc++a6995+aZtfbaa+9UFZLUmv2mXQFJmgTDTVKTDDdJTTLcJDXJcJPUJMNNUpMMN0lN2n/aFWhZkoOAo/qrO6rqwWnWR9qX2HKbgCT7J7kAuB34F+DDwG1JLkjyC9OtnbRvMNwm40Lgl4Ajq+oFVXUc8EzgycDfTLVmE5BkZZJMux7SoDj9aukluRk4uub9cpOsAG6oqrXTqdmeS/JC4D3AvcC7gI8AK+n9R3lmVV06xepJj/Ga22TU/GDrb5xNstz/N3k/8HbgScB/ACdX1ZVJng18DDDc1Al2Sydje5Iz529M8mrghinUZyntX1Wfr6pLgB9V1ZUAVbXcz0uNseU2GX8CfCrJa4Gr+ttmgIOB06ZWq6UxN/D5gXnfLfdWqRriNbcJSnIi8Nz+6vaqunya9VkKSWaB+4HQC+ufPfoVcFBVLcvR4CQ/YdfhHHqXGQ7by1XSHjLcJDXJa26SmtS5cEuycdp1mIRWzwvaPTfPa3nrXLgBrf7iWz0vaPfcPK9lrIvhJkl7rBMDCv1m8kaAAw888AXr16+fco2W3l133cWqVaumXY2JaPXcWj2vq6666qdVdeielPGKE55Y99w7O9zxrvv5ZVW1YU+ON45O3OdWVZuATQAzMzO1bdu2KddIaleSG/e0jHvuneWbl60Zat8VT7t55Z4ebxydCDdJy0sBczvdz909hpukkRXFwzVct3RaDDdJY7HlJqk5RTHbgcHIhRhuksYy1/HnJBhukkZWwKzhJqlFttwkNaeAh73mJqk1RdktldSggtluZ5vhJml0vRkK3Wa4SRpDmKXbr6o13CSNrDegYLhJakzvPjfDTVKD5my5SWqNLTdJTSrCbMffUmC4SRqL3VJJzSnCQ7Vi2tVYkOEmaWS9m3jtlkpqkAMKkppTFWbLlpukBs3ZcpPUmt6AQrfjo9u1k9RJDih03NyP1k67ChPziqcfM+0qaERfmLtk2lUYyaz3uUlqjTMUJDVrztFSSa3pTZw33CQ1pggPO/1KUmuq8CZeSS2KN/FKak9hy01SoxxQkNScIj6sUlJ7eq/263Z8dLt2kjqq+y9l7nanWVInFb0ZCsMsw0iyIcmNSXYkOWcX369J8qUk1yS5LskrFyvTcJM0ltl+622xZTFJVgAXAScD64Azkqybt9u5wCeq6ljgdOAfFivXbqmkkVVlKeeWHg/sqKpbAJJcDJwKbB88JHBY//OTgP9erFDDTdLIegMKSzb96nDgtoH124Ffm7fPO4HPJ3kD8ETgpMUKtVsqaQy9dygMswArk2wbWDaOccAzgH+uqtXAK4GPJFkwv2y5SRpZb0Bh6NHSu6tqZoHv7wCOGFhf3d826HXABoCquiLJQcBK4M7dFWrLTdJYZtlvqGUIW4G1SY5McgC9AYPN8/a5FXgZQJLnAAcBdy1UqC03SSNbyhkKVfVIkrOBy4AVwIeq6vok5wPbqmoz8GfAB5O8iV7D8ayqqoXKNdwkjWUpXxBTVVuALfO2nTfweTvwolHKNNwkjawKHp7r9lUtw03SyHrdUsNNUoP26bmlSVYn+bckNyf5XpK/64+GSFrGHr0VZJhlWiYWbkkCfAr4TFWtBY4GDgH+clLHlLS3ZEknzk/CJI98IvBgVf0TQFXNAm8CXpvkCRM8rqS9YK7/HoXFlmmZ5DW35wJXDW6oqv9LcitwFHDdBI8taYJ6o6W+2m9R/blmGwHWrFkz5dpIWsxyeMz4JLul24EXDG5IchiwBtgxuL2qNlXVTFXNrFq1aoJVkrRUut4tnWS4XQ48IcmZ8NgD6f6W3sz+n03wuJImbJ8eLe3P+zoN+L0kNwM3AQ8Cb5/UMSXtPV0fLZ3oNbequg141SSPIWnvqwqPOENBUou6PqBguEka2YgPq5wKw03SWAw3Sc1ZDve5GW6SxjLNe9iGYbhJGlkVPOLDKiW1yG6ppOZ4zU1Ss8pwk9QiBxQkNafKa26SmhRmHS2V1CKvuUlqjnNLJbWpetfdusxwkzQWR0slNaccUJDUKrulkprkaKmk5lQZbpIa5a0gkprkNbcOe+XzXjbtKkzMX33/c9OuwkSc+5wXT7sKov/Io46Plna7dpI6q4ZchpFkQ5Ibk+xIcs5u9vn9JNuTXJ/ko4uVuU+33CSNaQkHFJKsAC4CfhO4HdiaZHNVbR/YZy3wNuBFVXVfkqcsVq4tN0njWbqm2/HAjqq6paoeAi4GTp23zx8CF1XVfQBVdedihRpuksZSlaGWIRwO3Dawfnt/26CjgaOTfD3JlUk2LFao3VJJIytgbm7obunKJNsG1jdV1aYRD7k/sBZ4KbAa+EqSX62q/13oByRpNAUMf83t7qqaWeD7O4AjBtZX97cNuh34RlU9DHw/yU30wm7r7gq1WyppLFXDLUPYCqxNcmSSA4DTgc3z9vkMvVYbSVbS66beslChhpuk8SzRgEJVPQKcDVwGfBf4RFVdn+T8JKf0d7sMuCfJduBLwFur6p6FyrVbKmkMQw8WDKWqtgBb5m07b+BzAW/uL0Mx3CSNx+lXkppTUMOPlk6F4SZpTIabpBbZLZXUJMNNUnNGu4l3Kgw3SWNp5mGVSQ6sqp9PsjKSlpGOj5YuOkMhyfFJvg3c3F9/fpK/n3jNJHVaarhlWoaZfvU+4LeAewCq6lvACZOslKSOG3bq1RTDbZhu6X5V9YNkpybo7ITqI2lZSBMDCrclOR6o/uOA3wDcNNlqSeq8BgYUXk+va7oG+B/gi/1tkvZlc9OuwMIWDbf+s8pP3wt1kbRctHCfW5IPsosGaFVtHOJnZ4Fv05uENgucXVX/NUY9JXXMNEdChzFMt/SLA58PAk5j55c5LOSBqjoGIMkrgHcDLxmphpK6abmHW1V9fHA9yUeAr41xrMOA+8b4OUka2TjTr44EnjrkvgcnuZZei+9pwIm72inJRmAjwJo1a8aokqS9bdl3S5Pcx+MN0P2Ae4Fdvu5+Fwa7pb8OfDjJ+v4jgx/Tf83XJoCZmZmO/8ok9d7tt4wHFNK7c/f5PP6arbn5wTSsqrqi/9aaVcCib4uW1HEdb4YsOP2qH2Rbqmq2v4x9OkmeDaygP41L0vLW9bmlw1xzuzbJsVV1zRjlP3rNDXq3g7ymqpy6JbWg4y233YZbkv377xM8Ftia5HvA/fRCqqrquMUKr6oVS1ZTSd2yXMMN+CZwHHDKAvtI2gdNu8s5jIXCLQBV9b29VBdJy8kyHi1dlWS3b3euqvdOoD6Slonl3HJbARxC119OKGk6lnG4/bCqzt9rNZG0fLRwzU2SdmkZh9vL9lotJC076fjDKnc7Q6Gq7t2bFZGkpeRLmSWNZxl3SyVp15b5gIIk7Z7hJqlJHQ+3Yd44L0k7Cb3R0mGWocpLNiS5McmOJLt9GG6S301SSWYWK9NwkzS6IZ/lNsx1uf7L3i8CTgbWAWckWbeL/Q4F3gh8Y5gqGm6SxlNDLos7HthRVbdU1UPAxcCpu9jvXcBfAw8OU6jhJmk8Sxduh7Pz60Jv7297TJLjgCOq6rPDVs8BBUljGeFWkJVJtg2sb+q/FGq44yT7Ae8Fzhr6iBhuksY1fLjdXVULDQDcARwxsL6ax19KBXAosB74cu+dVfwysDnJKVU1GJo7Mdwkja6WdG7pVmBtkiPphdrpwB88dqiqHwMrH11P8mXgLQsFG3jNTdK4luiaW/9dLWcDlwHfBT5RVdcnOT/J2K85sOUmaSxLOf2qqrYAW+ZtO283+750mDL37XBb0e7Luc5df8K0qzARb9v+9WlXQY/q+AyFfTvcJI1n+Ns8psZwkzSy4FNBJDXKcJPUJsNNUpMMN0nN8Um8kppluElqUddf7We4SRqL3VJJ7fEmXknNMtwktcYZCpKalblup5vhJml0XnOT1Cq7pZLaZLhJapEtN0ltMtwkNWdp3341EYabpJF5n5ukdlW3081wkzQWW26S2uNNvDtL8tOqOmRvHlPSZDigIKlJhpuk9hSdH1DYb9oVAEiyMcm2JNvuuuuuaVdH0hBSwy3T0olwq6pNVTVTVTOrVq2adnUkDaOGXKbEbqmkkXkTr6Q2VfmwSkmN6na27d1w8x43qR12SyW1pwC7pZKa1O1s68atIJKWn6W8zy3JhiQ3JtmR5JxdfP/mJNuTXJfk8iS/sliZhpuksWSuhloWLSdZAVwEnAysA85Ism7ebtcAM1X1POCTwAWLlWu4SRrdsDfwDtdyOx7YUVW3VNVDwMXAqTsdrupLVfWz/uqVwOrFCjXcJI2sdxNvDbUM4XDgtoH12/vbdud1wOcWK9QBBUnjGf6pICuTbBtY31RVm8Y5ZJJXAzPASxbb13CTNJYhW2UAd1fVzALf3wEcMbC+ur9t5+MlJwHvAF5SVT9f7KB2SyWNbmmvuW0F1iY5MskBwOnA5sEdkhwLfAA4paruHKZQW26SxrB0c0ur6pEkZwOXASuAD1XV9UnOB7ZV1WbgQuAQ4JIkALdW1SkLlWu4SRrPEj6ssqq2AFvmbTtv4PNJo5ZpuEkanS9lltSsjj9m3HCTNJ5uZ5vhJmk8met2v9RwkzS6YpSbeKfCcJM0sjD01KqpMdwkjcdwk9Qkw01Sc7zmJqlVjpZKalDZLe2yS3940bSrIC1PheEmqVHd7pUabpLG431uktpkuElqThXMdrtfarhJGo8tN0lNMtwkNaeAJXqHwqQYbpLGUFBec5PUmsIBBUmN8pqbpCYZbpLa48R5SS0qwEceSWqSLTdJ7XH6laQWFZT3uUlqkjMUJDXJa26SmlPlaKmkRtlyk9SeomZnp12JBRlukkbnI48kNctbQSS1poCy5SapOeXDKiU1qusDCqkODOcm2Qhs7K+uB74zxepMykrg7mlXYkJaPbdWz+tZVXXonhSQ5FJ6v59h3F1VG/bkeOPoRLgNSrKtqmamXY+l1up5Qbvn5nktb/tNuwKSNAmGm6QmdTHcNk27AhMy1fNKMpvk2iTfSXJJkifsQVkvTfLv/c+nALcusO+Tk/zxGMd4Z5K3jFvHJeLf4jLWuXCrqiZ/8R04rweq6piqWg88BPzR4JfpGfnvoao2V9XvLLDLk4GRw60LOvBvNhGtntd8nQs37RVfBY5K8owkNyb5ML0R6iOSvDzJFUmu7rfwDgFIsiHJDUmuBh4LsyRnJXl///NTk3w6ybf6y28A7wGe2W81Xtjf761Jtia5LslfDJT1jiQ3Jfka8Ky99ttQk7zPbR+TZH/gZODS/qa1wGuq6sokK4FzgZOq6v4kfw68OckFwAeBE4EdwMd3U/z7gP+sqtOSrAAOAc4B1lfVMf3jv7x/zOOBAJuTvBi4HzgdOIbe3+XVwFVLe/balxhu+46Dk1zb//xV4B+BpwM/qKor+9tfCKwDvp4E4ADgCuDZwPer6maAJP/K4/clDjoROBOgqmaBHyf5xXn7vLy/XNNfP4Re2B0KfLqqftY/xuY9Olvt8wy3fccDj7aeHtUPsPsHNwFfqKoz5u2308/toQDvrqoPzDvGny7hMSSvuWknVwIvSnIUQJInJjkauAF4RpJn9vc7Yzc/fznw+v7PrkjyJOAn9Fplj7oMeO3AtbzDkzwF+Arw20kOTnIo8KolPjftYww3Paaq7gLOAj6W5Dr6XdKqepBeN/Sz/QGFO3dTxBuBE5J8m971snVVdQ+9bu53klxYVZ8HPgpc0d/vk8ChVXU1vWt53wI+B2yd2Ilqn9C56VeStBRsuUlqkuEmqUmGm6QmGW6SmmS4SWqS4SapSYabpCYZbpKa9P8yh9Qf4hpfGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nemo.core.NeuralModuleFactory.reset_trainer(nf)\n",
    "\n",
    "nf.train(\n",
    "    tensors_to_optimize=[train_loss],\n",
    "    callbacks=[train_callback, tensorboard_callback, eval_callback, ckpt_callback],\n",
    "    lr_policy=lr_policy_fn,\n",
    "    optimizer=OPTIMIZER,\n",
    "    optimization_params={\"num_epochs\": NUM_EPOCHS, \"lr\": LEARNING_RATE, \"weight_decay\": WEIGHT_DECAY}\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results should look something like:\n",
    "```\n",
    "[NeMo I 2020-05-22 17:13:48 token_classification_callback:82] Accuracy: 0.9882348032875798\n",
    "[NeMo I 2020-05-22 17:13:48 token_classification_callback:86] F1 weighted: 98.82\n",
    "[NeMo I 2020-05-22 17:13:48 token_classification_callback:86] F1 macro: 93.74\n",
    "[NeMo I 2020-05-22 17:13:48 token_classification_callback:86] F1 micro: 98.82\n",
    "[NeMo I 2020-05-22 17:13:49 token_classification_callback:89] precision    recall  f1-score   support\n",
    "    \n",
    "    O (label id: 0)     0.9938    0.9957    0.9947     22092\n",
    "    B (label id: 1)     0.8843    0.9034    0.8938       787\n",
    "    I (label id: 2)     0.9505    0.8982    0.9236      1090\n",
    "    \n",
    "           accuracy                         0.9882     23969\n",
    "          macro avg     0.9429    0.9324    0.9374     23969\n",
    "       weighted avg     0.9882    0.9882    0.9882     23969\n",
    "```\n",
    "The final confusion matrix visualization shows a bright diagonal, indicating that the predicted label matched the true label with high accuracy for all the label types (IOB).\n",
    "\n",
    "<img src=\"../images/ner_confusion_matrix.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Inference\n",
    "We have a test set, which we can read with *pandas*, then sample and export into whatever format we need.  We ultimately want a manageable number of sentences in a list, that we can submit directly to a data layer neural module.  In the text classification example, we provided the data layer with a filename, but this time, we'll just pass a query list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the test samples DataFrame: (450, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clustering of missense mutations in the ataxia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ataxia - telangiectasia ( A - T ) is a recessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The risk of cancer , especially lymphoid neopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>By analysing tumour DNA from patients with spo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In marked contrast to the ATM mutation pattern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  Clustering of missense mutations in the ataxia...\n",
       "1  Ataxia - telangiectasia ( A - T ) is a recessi...\n",
       "2  The risk of cancer , especially lymphoid neopl...\n",
       "3  By analysing tumour DNA from patients with spo...\n",
       "4  In marked contrast to the ATM mutation pattern..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the text data and sanity-check it \n",
    "df_test = pd.read_csv(DATA_DIR + 'text_test.txt', sep='\\t', names=['sentence'])\n",
    "print('The size of the test samples DataFrame: {}'.format(df_test.shape))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We conclude that these mice very closely mimic severe human von Willebrand disease and will be very useful for investigating the role of vWf in normal physiology and in disease models . . ', 'We report here the complete characterization of the 48 exons of the COL4A4 gene , a comprehensive gene screen , and the subsequent detection of 10 novel mutations in eight patients diagnosed with autosomal recessive Alport syndrome . ', 'In a survey of DM in Northern Ireland , 59 pedigrees were ascertained . ', 'PAX6 regulates eye development in animals ranging from jellyfish to Drosophila to humans . ', 'Deficiency of the sixth component of human complement ( C6 ) has been reported in a number of families from the western Cape , South Africa . ', 'Three of 13 uninformative patients had constitutional deletions . ', 'Molecular genetic analysis of her VLCAD gene revealed a T1372C ( F458L ) missense mutation and a 1668 ACAG 1669 splice site mutation . ', 'The analysis of tumors from 54 ( 71 % ) of 76 informative patients showed loss of constitutional heterozygosity ( LOH ) at intragenic loci . ', 'Human complement factor H deficiency associated with hemolytic uremic syndrome . ', 'In specific C5 titrations , however , it was noted that when limited amounts of C5 were assayed in the presence of low dilutions of either C5D serum , curving rather than linear dose - response plots were consistently obtained , suggesting some inhibitory effect . ']\n"
     ]
    }
   ],
   "source": [
    "# Grab a small number (such as 10) of random samples and save them\n",
    "df_test = df_test.sample(10)\n",
    "df_test.shape\n",
    "queries = df_test['sentence'].values.tolist()\n",
    "print(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.1 Create the Test Graph\n",
    "<figure>\n",
    "    <img src=\"../images/nemo/ner_test_graph.png\" width=600>\n",
    "    <figcaption style=\"text-align:center;\">Test Graph</figcaption>\n",
    "</figure>\n",
    "\n",
    "We'll use a different data layer neural module called `BertTokenClassificationInferDataLayer`, so that we can use a direct list as input instead of a file (the `queries=` parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:116] Max length: 59\n",
      "[NeMo I 2020-07-25 22:18:02 data_preprocessing:250] Min: 16 |                  Max: 59 |                  Mean: 33.8 |                  Median: 34.0\n",
      "[NeMo I 2020-07-25 22:18:02 data_preprocessing:252] 75 percentile: 40.5\n",
      "[NeMo I 2020-07-25 22:18:02 data_preprocessing:253] 99 percentile: 58.190000000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-07-25 22:18:02 token_classification_dataset:145] 0 are longer than 59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:149] i: 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:150] subtokens: [CLS] We conclude that these mice very closely mimic severe human von Will ##eb ##rand disease and will be very useful for investigating the role of v ##W ##f in normal physiology and in disease models . . [SEP]\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:153] subtokens_mask: 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:149] i: 1\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:150] subtokens: [CLS] We report here the complete characterization of the 48 ex ##ons of the CO ##L ##4 ##A ##4 gene , a comprehensive gene screen , and the subsequent detection of 10 novel mutations in eight patients diagnosed with auto ##so ##mal re ##cess ##ive Al ##port syndrome . [SEP]\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:153] subtokens_mask: 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:149] i: 2\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:150] subtokens: [CLS] In a survey of D ##M in Northern Ireland , 59 p ##ed ##ig ##ree ##s were as ##cer ##tain ##ed . [SEP]\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:153] subtokens_mask: 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:149] i: 3\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:150] subtokens: [CLS] PA ##X ##6 regulate ##s eye development in animals ranging from j ##elly ##fish to Dr ##oso ##phi ##la to humans . [SEP]\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:153] subtokens_mask: 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:149] i: 4\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:150] subtokens: [CLS] De ##ficiency of the sixth component of human complement ( C ##6 ) has been reported in a number of families from the western Cape , South Africa . [SEP]\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2020-07-25 22:18:02 token_classification_dataset:153] subtokens_mask: 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "# Define a data layer neural module for the test set\n",
    "dl_test = BertTokenClassificationInferDataLayer(\n",
    "    tokenizer=tokenizer,\n",
    "    queries=queries,\n",
    "    max_seq_length=MAX_SEQ_LEN,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all the neural graph connections\n",
    "test_data = dl_test()\n",
    "test_embeddings = lm(input_ids=test_data.input_ids, \n",
    "                           token_type_ids=test_data.input_type_ids, \n",
    "                           attention_mask=test_data.input_mask)\n",
    "test_logits = classifier(hidden_states=test_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.2 Run Inference on the Test Set\n",
    "Start the action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-07-25 22:18:02 actions:695] Evaluating batch 0 out of 10\n",
      "[NeMo I 2020-07-25 22:18:02 actions:695] Evaluating batch 1 out of 10\n",
      "[NeMo I 2020-07-25 22:18:02 actions:695] Evaluating batch 2 out of 10\n",
      "[NeMo I 2020-07-25 22:18:02 actions:695] Evaluating batch 3 out of 10\n",
      "[NeMo I 2020-07-25 22:18:02 actions:695] Evaluating batch 4 out of 10\n",
      "[NeMo I 2020-07-25 22:18:03 actions:695] Evaluating batch 5 out of 10\n",
      "[NeMo I 2020-07-25 22:18:03 actions:695] Evaluating batch 6 out of 10\n",
      "[NeMo I 2020-07-25 22:18:03 actions:695] Evaluating batch 7 out of 10\n",
      "[NeMo I 2020-07-25 22:18:03 actions:695] Evaluating batch 8 out of 10\n",
      "[NeMo I 2020-07-25 22:18:03 actions:695] Evaluating batch 9 out of 10\n"
     ]
    }
   ],
   "source": [
    "test_logits_tensors = nf.infer(tensors=[test_logits, test_data.subtokens_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5.3 Inference Results\n",
    "To view the results, we'll gather the resulting output tensors and map them to the words in the `queries` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the results\n",
    "def concatenate(lists):\n",
    "    return np.concatenate([t.cpu() for t in lists])\n",
    "\n",
    "def add_brackets(text, add=True):\n",
    "    return '[' + text + ']' if add else text\n",
    "\n",
    "logits, subtokens_mask = [concatenate(tensors) for tensors in test_logits_tensors]\n",
    "preds = np.argmax(logits, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "We conclude that these mice very closely mimic severe human von Willebrand disease and will be very useful for investigating the role of vWf in normal physiology and in disease models . . \n",
      "\u001b[34m----------------------------\u001b[0m\n",
      "Labeled Result:\n",
      "We conclude that these mice very closely mimic severe human von[B] Willebrand[I] disease[I] and will be very useful for investigating the role of vWf in normal physiology and in disease models . .\n",
      "\u001b[32m*****************************\n",
      "*****************************\u001b[0m\n",
      "Query:\n",
      "We report here the complete characterization of the 48 exons of the COL4A4 gene , a comprehensive gene screen , and the subsequent detection of 10 novel mutations in eight patients diagnosed with autosomal recessive Alport syndrome . \n",
      "\u001b[34m----------------------------\u001b[0m\n",
      "Labeled Result:\n",
      "We report here the complete characterization of the 48 exons of the COL4A4 gene , a comprehensive gene screen , and the subsequent detection of 10 novel mutations in eight patients diagnosed with autosomal recessive Alport[I] syndrome[I] .\n",
      "\u001b[32m*****************************\n",
      "*****************************\u001b[0m\n",
      "Query:\n",
      "In a survey of DM in Northern Ireland , 59 pedigrees were ascertained . \n",
      "\u001b[34m----------------------------\u001b[0m\n",
      "Labeled Result:\n",
      "In a survey of DM[B] in Northern Ireland , 59 pedigrees were ascertained .\n",
      "\u001b[32m*****************************\n",
      "*****************************\u001b[0m\n",
      "Query:\n",
      "PAX6 regulates eye development in animals ranging from jellyfish to Drosophila to humans . \n",
      "\u001b[34m----------------------------\u001b[0m\n",
      "Labeled Result:\n",
      "PAX6 regulates eye development in animals ranging from jellyfish to Drosophila to humans .\n",
      "\u001b[32m*****************************\n",
      "*****************************\u001b[0m\n",
      "Query:\n",
      "Deficiency of the sixth component of human complement ( C6 ) has been reported in a number of families from the western Cape , South Africa . \n",
      "\u001b[34m----------------------------\u001b[0m\n",
      "Labeled Result:\n",
      "Deficiency[B] of[I] the[I] sixth[I] component[I] of[I] human[I] complement[I] ( C6 ) has been reported in a number of families from the western Cape , South Africa .\n",
      "\u001b[32m*****************************\n",
      "*****************************\u001b[0m\n",
      "Query:\n",
      "Three of 13 uninformative patients had constitutional deletions . \n",
      "\u001b[34m----------------------------\u001b[0m\n",
      "Labeled Result:\n",
      "Three of 13 uninformative patients had constitutional deletions .\n",
      "\u001b[32m*****************************\n",
      "*****************************\u001b[0m\n",
      "Query:\n",
      "Molecular genetic analysis of her VLCAD gene revealed a T1372C ( F458L ) missense mutation and a 1668 ACAG 1669 splice site mutation . \n",
      "\u001b[34m----------------------------\u001b[0m\n",
      "Labeled Result:\n",
      "Molecular genetic analysis of her VLCAD gene revealed a T1372C ( F458L ) missense mutation and a 1668 ACAG 1669 splice site mutation .\n",
      "\u001b[32m*****************************\n",
      "*****************************\u001b[0m\n",
      "Query:\n",
      "The analysis of tumors from 54 ( 71 % ) of 76 informative patients showed loss of constitutional heterozygosity ( LOH ) at intragenic loci . \n",
      "\u001b[34m----------------------------\u001b[0m\n",
      "Labeled Result:\n",
      "The analysis of tumors[B] from 54 ( 71 % ) of 76 informative patients showed loss of constitutional heterozygosity ( LOH ) at intragenic loci .\n",
      "\u001b[32m*****************************\n",
      "*****************************\u001b[0m\n",
      "Query:\n",
      "Human complement factor H deficiency associated with hemolytic uremic syndrome . \n",
      "\u001b[34m----------------------------\u001b[0m\n",
      "Labeled Result:\n",
      "Human complement[I] factor[I] H[I] deficiency[I] associated with hemolytic[B] uremic[I] syndrome[I] .\n",
      "\u001b[32m*****************************\n",
      "*****************************\u001b[0m\n",
      "Query:\n",
      "In specific C5 titrations , however , it was noted that when limited amounts of C5 were assayed in the presence of low dilutions of either C5D serum , curving rather than linear dose - response plots were consistently obtained , suggesting some inhibitory effect . \n",
      "\u001b[34m----------------------------\u001b[0m\n",
      "Labeled Result:\n",
      "In specific C5 titrations , however , it was noted that when limited amounts of C5 were assayed in the presence of low dilutions of either C5D[B] serum , curving rather than linear dose - response plots were consistently obtained , suggesting some inhibitory effect .\n",
      "\u001b[32m*****************************\n",
      "*****************************\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the queries and display the IOB tags\n",
    "blue_separator = termcolor.colored('----------------------------', color='blue')\n",
    "green_separator = termcolor.colored('*****************************\\n*****************************', color='green')\n",
    "labels_dict = DATA_DIR + \"label_ids.csv\"\n",
    "labels_dict = get_vocab(labels_dict)\n",
    "\n",
    "for i, query in enumerate(queries):\n",
    "    print(f'Query:\\n{query}')\n",
    "    \n",
    "    pred = preds[i][subtokens_mask[i] > 0.5]\n",
    "    words = query.strip().split()\n",
    "    output = ''\n",
    "    \n",
    "    for j, w in enumerate(words):\n",
    "        output += w\n",
    "        label = labels_dict[pred[j]]\n",
    "        if label != NONE_LABEL:\n",
    "            label = add_brackets(label)\n",
    "            output += label\n",
    "        output += ' '\n",
    "        \n",
    "    print(f'{blue_separator}\\nLabeled Result:\\n{output.strip()}\\n{green_separator}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6 Exercise: Change the Language Model\n",
    "Now that you've built the project, you can experiment with different settings, and try the BioMegatron model.   To do that, you'll need to restart the kernel to clear memory, and change the `MODEL_TYPE` value in the [4.1.1 Input Parameters](4.1.1-Input-Parameters) section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "You've built a NER project that recognizes disease names.  You're ready to take your assessmet.<br>\n",
    "\n",
    "Move on to [5.0 Assessment](050_Assessment.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"../images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
